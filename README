ðŸ‡®ðŸ‡³ Project Samarth (Samarth: Capable/Empowered)Project Samarth for Bharat Fellowship 2025Project Samarth is an intelligent, agent-based Q&A system designed to synthesize complex data from Indian government sources, specifically focusing on agriculture and climate. It aims to empower policy makers and analysts with quick, data-driven insights by leveraging large language models (LLMs) and local database querying (DuckDB).Key ComponentsFileDescriptionet1.pyETL Script: Fetches, cleans, and transforms raw data from data.gov.in using the DATA.GOV.IN API, storing the structured results in a local DuckDB file (samarth.db).agent.pyAI Agent: Defines the LLM-powered agent using LangChain and OpenAI. It includes specialized Python tools (functions) to query the DuckDB database for crop production, rainfall, and correlation analysis.app.pyFrontend: The Streamlit application that provides a clean, interactive chat interface for users to interact with the Samarth AI Agent.ðŸš€ Getting Started1. PrerequisitesPython 3.8+A Streamlit-compatible environment (local machine or cloud host).2. Environment SetupThe project requires two critical API keys. Create a file named .env in the root directory and populate it with your keys:# .env file content
OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"
DATA_GOV_API_KEY="YOUR_DATA_GOV_API_KEY_HERE"
OpenAI API Key (OPENAI_API_KEY): Required for the LLM agent (GPT-4o) to interpret user questions, reason, and generate final, citable answers.Data.gov.in API Key (DATA_GOV_API_KEY): Required by the et1.py script to fetch the agricultural and climate datasets from the government portal.3. Install DependenciesInstall the necessary Python libraries using the provided requirements.txt:pip install -r requirements.txt
ðŸ›  UsageStep 1: Run the ETL ProcessBefore running the AI Agent, you must first fetch the data and build the local DuckDB database.Ensure your DATA_GOV_API_KEY is set in the .env file.Run the ETL script from your terminal:python et1.py
# This script will fetch data from the two defined resources, clean it, and create a file named 'samarth.db'.
Step 2: Launch the Streamlit ApplicationOnce samarth.db is created, you can launch the interactive chat interface.Ensure your OPENAI_API_KEY is set in the .env file.Run the Streamlit application:streamlit run app.py
The application will open in your web browser, and you can begin asking questions like:"What were the top 5 crops produced in Punjab in 2010?""What was the average annual rainfall in the Marathwada subdivision between 2005 and 2015?""Correlate Wheat production in Haryana with its annual rainfall from 2000 to 2010."ðŸ“š Data SourcesThe ETL process currently sources data from the following data.gov.in resources, with full citation provided by the AI Agent in its final response:Agriculture Production: District-wise and Season-wise Crop Production Statistics (1997 onwards)Climate Rainfall: Sub-divisional Monthly Rainfall (1901-2017)
